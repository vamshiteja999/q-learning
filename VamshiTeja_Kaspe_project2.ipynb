{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name:Vamshiteja Kaspe     \n",
        "     Znumber:z23733757           \n",
        "\n",
        "     google collab link:https://colab.research.google.com/drive/1_WZXBzSd4eGrB3Jt8oexR2snyXLWLfb5?usp=sharing"
      ],
      "metadata": {
        "id": "W4fB-_0lyydM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sjQAfpcEsw0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Establish the Environment"
      ],
      "metadata": {
        "id": "W5Vq--KWujtb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Azn_RmPrU8y"
      },
      "outputs": [],
      "source": [
        "# Define the dimensions of the delivery area (i.e., its states)\n",
        "delivery_area_rows = 10\n",
        "delivery_area_columns = 10\n",
        "\n",
        "# Create a 3D numpy array to store the current Q-values for each state and action pair: Q(s, a)\n",
        "# The array comprises 10 rows and 10 columns (to match the shape of the delivery area), along with a third \"action\" dimension.\n",
        "# The \"action\" dimension consists of 4 layers that help us track the Q-values for each possible action in each state.\n",
        "# The initial value of each (state, action) pair is set to 0.\n",
        "q_values = np.zeros((delivery_area_rows, delivery_area_columns, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Actions"
      ],
      "metadata": {
        "id": "X5ZTzgY5uqV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define actions\n",
        "#numeric action codes: 0 = up, 1 = right, 2 = down, 3 = left\n",
        "actions = ['up', 'right', 'down', 'left']"
      ],
      "metadata": {
        "id": "tfNAYs55rWqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rewards"
      ],
      "metadata": {
        "id": "tG14i5A6u9oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2D numpy array to store the rewards for each state.\n",
        "# The array consists of 10 rows and 10 columns (matching the shape of the delivery area),\n",
        "# with each value initialized to -100.\n",
        "rewards = np.full((delivery_area_rows, delivery_area_columns), -100.)\n",
        "rewards[0, 5] = 100.  # Set the reward for the packaging area (i.e., the goal) to 100\n",
        "\n",
        "# Define aisle locations (i.e., white squares) for rows 1 through 9\n",
        "aisles = {}  # Store locations in a dictionary\n",
        "aisles[1] = [i for i in range(1, 10)]\n",
        "aisles[2] = [1, 7, 9]\n",
        "aisles[3] = [i for i in range(1, 8)]\n",
        "aisles[3].append(9)\n",
        "aisles[4] = [3, 7]\n",
        "aisles[5] = [i for i in range(10)]\n",
        "aisles[6] = [5]\n",
        "aisles[7] = [i for i in range(1, 10)]\n",
        "aisles[8] = [3, 7]\n",
        "aisles[9] = [i for i in range(10)]\n",
        "\n",
        "# Set the rewards for all aisle locations (i.e., white squares)\n",
        "for row_index in range(1, 10):\n",
        "    for column_index in aisles[row_index]:\n",
        "        rewards[row_index, column_index] = -1.\n",
        "\n",
        "# Print rewards matrix\n",
        "for row in rewards:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Bmw8HorbZS",
        "outputId": "958b2d45-1141-4c40-9e7f-2a8165ebaf16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100. -100. -100. -100. -100.  100. -100. -100. -100. -100.]\n",
            "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
            "[-100.   -1. -100. -100. -100. -100. -100.   -1. -100.   -1.]\n",
            "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.   -1.]\n",
            "[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100.]\n",
            "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
            "[-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100.]\n",
            "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
            "[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100.]\n",
            "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Helper Functions"
      ],
      "metadata": {
        "id": "vHXHYWSavjD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to determine if the specified location is a terminal state\n",
        "def is_terminal_state(current_row_index, current_column_index):\n",
        "    # If the reward for this location is -1, it is not a terminal state (i.e., a 'white square')\n",
        "    if rewards[current_row_index, current_column_index] == -1.:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "# Define a function to choose a random, non-terminal starting location\n",
        "def get_starting_location():\n",
        "    current_row_index = np.random.randint(delivery_area_rows)\n",
        "    current_column_index = np.random.randint(delivery_area_columns)\n",
        "    # Continue choosing random row and column indexes until a non-terminal state is identified\n",
        "    while is_terminal_state(current_row_index, current_column_index):\n",
        "        current_row_index = np.random.randint(delivery_area_rows)\n",
        "        current_column_index = np.random.randint(delivery_area_columns)\n",
        "    return current_row_index, current_column_index\n",
        "\n",
        "# Define an epsilon-greedy algorithm to choose the next action (i.e., where to move next)\n",
        "def get_next_action(current_row_index, current_column_index, epsilon):\n",
        "    if np.random.random() < epsilon:\n",
        "        return np.argmax(q_values[current_row_index, current_column_index])\n",
        "    else:\n",
        "        return np.random.randint(4)\n",
        "\n",
        "# Define a function to get the next location based on the chosen action\n",
        "def get_next_location(current_row_index, current_column_index, action_index):\n",
        "    new_row_index = current_row_index\n",
        "    new_column_index = current_column_index\n",
        "    if actions[action_index] == 'up' and current_row_index > 0:\n",
        "        new_row_index -= 1\n",
        "    elif actions[action_index] == 'right' and current_column_index < delivery_area_columns - 1:\n",
        "        new_column_index += 1\n",
        "    elif actions[action_index] == 'down' and current_row_index < delivery_area_rows - 1:\n",
        "        new_row_index += 1\n",
        "    elif actions[action_index] == 'left' and current_column_index > 0:\n",
        "        new_column_index -= 1\n",
        "    return new_row_index, new_column_index\n",
        "\n",
        "# Define a function to get the shortest path between any location within the delivery area that\n",
        "# the drone is allowed to travel and the item packaging location.\n",
        "def get_shortest_path(start_row_index, start_column_index):\n",
        "    if is_terminal_state(start_row_index, start_column_index):\n",
        "        return []\n",
        "    else:\n",
        "        current_row_index, current_column_index = start_row_index, start_column_index\n",
        "        shortest_path = []\n",
        "        shortest_path.append([current_row_index, current_column_index])\n",
        "        while not is_terminal_state(current_row_index, current_column_index):\n",
        "            action_index = get_next_action(current_row_index, current_column_index, 1.)\n",
        "            current_row_index, current_column_index = get_next_location(current_row_index, current_column_index, action_index)\n",
        "            shortest_path.append([current_row_index, current_column_index])\n",
        "        return shortest_path\n"
      ],
      "metadata": {
        "id": "uIO2BXTfr_ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the AI Agent using Q-Learning"
      ],
      "metadata": {
        "id": "jC_dUqB5vrd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "exploration_rate = 0.9  # The percentage of time when we explore (choose a random action) instead of exploiting the best action\n",
        "discount_factor = 0.9  # Discount factor for future rewards\n",
        "learning_rate = 0.9  # The rate at which the AI agent learns\n",
        "\n",
        "# Run through 1000 training episodes\n",
        "for episode in range(1000):\n",
        "    # Get the starting location for this episode\n",
        "    row_index, column_index = get_starting_location()\n",
        "\n",
        "    # Continue taking actions (i.e., moving) until reaching a terminal state\n",
        "    # (i.e., reaching the item packaging area or crashing into an item storage location)\n",
        "    while not is_terminal_state(row_index, column_index):\n",
        "        # Choose which action to take (i.e., where to move next)\n",
        "        action_index = get_next_action(row_index, column_index, exploration_rate)\n",
        "\n",
        "        # Perform the chosen action and transition to the next state (i.e., move to the next location)\n",
        "        old_row_index, old_column_index = row_index, column_index  # Store the old row and column indexes\n",
        "        row_index, column_index = get_next_location(row_index, column_index, action_index)\n",
        "\n",
        "        # Receive the reward for moving to the new state and calculate the temporal difference\n",
        "        reward = rewards[row_index, column_index]\n",
        "        old_q_value = q_values[old_row_index, old_column_index, action_index]\n",
        "        temporal_difference = reward + (discount_factor * np.max(q_values[row_index, column_index])) - old_q_value\n",
        "\n",
        "        # Update the Q-value for the previous state and action pair\n",
        "        new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
        "        q_values[old_row_index, old_column_index, action_index] = new_q_value\n",
        "\n",
        "print('Training complete!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zehenkm2sT-r",
        "outputId": "3513aab6-b304-408a-9543-474685e4375d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve Optimal Routes"
      ],
      "metadata": {
        "id": "LVh1dFf-v25s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a few shortest paths\n",
        "print(get_shortest_path(3, 9))  # Starting at row 2, column 8\n",
        "print(get_shortest_path(5, 0))  # Starting at row 4, column 1\n",
        "print(get_shortest_path(9, 5))  # Starting at row 8, column 7\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Jx4EA-suAi",
        "outputId": "26e3255b-1abd-4c60-9f0a-5a90d28e6173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 9], [2, 9], [1, 9], [1, 8], [1, 7], [1, 6], [1, 5], [0, 5]]\n",
            "[[5, 0], [5, 1], [5, 2], [5, 3], [4, 3], [3, 3], [3, 2], [3, 1], [2, 1], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [0, 5]]\n",
            "[[9, 5], [9, 6], [9, 7], [8, 7], [7, 7], [7, 6], [7, 5], [6, 5], [5, 5], [5, 6], [5, 7], [4, 7], [3, 7], [2, 7], [1, 7], [1, 6], [1, 5], [0, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display an example of a reversed shortest path\n",
        "example_path = get_shortest_path(5, 2)  # Go to row 3, column 7\n",
        "example_path.reverse()\n",
        "print(example_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBUDQQyKuK4R",
        "outputId": "56cb1499-6481-4532-cea3-3dc93760c9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 5], [1, 5], [1, 4], [1, 3], [1, 2], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [5, 3], [5, 2]]\n"
          ]
        }
      ]
    }
  ]
}